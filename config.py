PRETRAIN_DATA_PATH="./data"
VOCAB_FILE="ice_text.model"
VOCAB_SIZE=150344
d_model = 768
num_layers = 12
num_heads = 12
d_ff = 3072 # d_ff 代表的是前馈网络（Feed-Forward Network）中的隐藏层大小。在Transformer架构中，前馈神经网络通常包含一个两个线性变换和一个非线性激活函数。具体来说，前馈网络的计算过程如下：
max_len = 2048
dropout_rate = 0.1
output_dir="./output"
batch_size_per_gpu=2
gradient_accumulation_steps=16
save_steps=10000000
seed=1024
warmup_steps=10
learning_rate=1e-5
logging_steps=100
epochs=1